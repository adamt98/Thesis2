{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a22a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cProfile import label\n",
    "from re import T\n",
    "from Environments2 import BarrierEnv, BarrierEnv2\n",
    "from Generators import GBM_Generator\n",
    "import Models\n",
    "import Utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9184c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#writer = SummaryWriter()\n",
    "from Models import DeltaHedge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bd5525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f266697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfffbb9d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.logger import Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9490d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FigureRecorderCallback(BaseCallback):\n",
    "    def __init__(self, test_env, verbose=0):\n",
    "        super(FigureRecorderCallback, self).__init__(verbose)\n",
    "        self.test_env = test_env\n",
    "\n",
    "    def _on_step(self): return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        figure = plt.figure()\n",
    "\n",
    "        obs = self.test_env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action, _states = self.model.predict(obs, deterministic=False)\n",
    "            obs, reward, done, info = self.test_env.step(action)\n",
    "        \n",
    "    \n",
    "        model_actions = info['output'].actions.values\n",
    "\n",
    "        # delta hedge benchmark\n",
    "        obs = self.test_env.reset()\n",
    "        delta_agent = DeltaHedge(self.test_env.generator.initial, n_puts_sold=n_puts_sold, min_action=min_action)\n",
    "        delta_actions = delta_agent.test(self.test_env, obs).actions.values\n",
    "\n",
    "        figure.add_subplot().plot(delta_actions, 'b-', model_actions, 'g-')\n",
    "        \n",
    "        # Close the figure after logging it\n",
    "        self.logger.record(\"trajectory/figure\", Figure(figure, close=True), exclude=(\"stdout\", \"log\", \"json\", \"csv\"))\n",
    "        plt.close()\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d36aff",
   "metadata": {},
   "source": [
    "#### Environment config ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e533473",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.005*np.sqrt(250) # 1% vol per day, annualized\n",
    "r = 0.0 # Annualized\n",
    "S0 = 100\n",
    "freq = 0.2 #0.2 corresponds to trading freq of 5x per day\n",
    "ttm = 50 # 50 & freq=0.2 => 10 days expiry\n",
    "kappa = 1.0\n",
    "cost_multiplier = 0.0\n",
    "discount = 0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ef9778",
   "metadata": {},
   "outputs": [],
   "source": [
    "barrier = 90\n",
    "n_puts_sold = 1\n",
    "min_action = -100\n",
    "max_action = 100\n",
    "action_num = max_action - min_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf83b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = GBM_Generator(S0, r, sigma, freq, barrier=barrier)\n",
    "env_args = {\n",
    "    \"generator\" : generator,\n",
    "    \"ttm\" : ttm,\n",
    "    \"kappa\" : kappa,\n",
    "    \"cost_multiplier\" : cost_multiplier,\n",
    "    \"reward_type\" : \"static\",\n",
    "    \"testing\" : False,\n",
    "    \"n_puts_sold\" : n_puts_sold,\n",
    "    \"min_action\" : min_action,\n",
    "    \"max_action\" : max_action\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5174e2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BarrierEnv(**env_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8e1b09",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "##### PPO Training hyperparameter setup ######\n",
    "n_sim = 100\n",
    "observe_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f864fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_episodes = 50*24000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509a6d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 3000*50 # roll out 3000 episodes, then train\n",
    "n_epochs = 5 # 5 <=> pass over the rollout 5 times\n",
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f888cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_kwargs = dict(activation_fn=torch.nn.LeakyReLU,\n",
    "                     net_arch=[32,32, dict(pi=[32,32], vf=[32])]) # dict(pi=[10], vf=[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bdf9cc",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "gradient_max = 1.0\n",
    "gae_lambda = 0.96\n",
    "value_weight = 1.0\n",
    "entropy_weight = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a4dbe6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def lr(x : float): \n",
    "    return 1e-3\n",
    "    #return 1e-5 + (5e-4-1e-5)*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551d094a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "#lr=3e-5\n",
    "surrogate_loss_clip = 0.1 # min and max acceptable KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5e433c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def simulate(env, obs):\n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs, deterministic=False)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "    \n",
    "    return info['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7f5a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # vals = []\n",
    "    # vals2 = []\n",
    "    # deltas = []\n",
    "    # delta2 = []\n",
    "    # spots = np.arange(40, 120, 0.1)\n",
    "    # for spot in spots:\n",
    "    #     ttm1 = 1\n",
    "    #     barrier = 90\n",
    "    #     generator = GBM_Generator(spot, r, sigma, freq, barrier=barrier)\n",
    "    #     val = generator.get_barrier_value(K=100, ttm=ttm1, up=False, out=False, call=False)\n",
    "    #     val2 = generator.get_option_value(K=100, ttm=ttm1, call=False)\n",
    "    #     delta_barr = generator.get_DIP_delta(spot, K=100, ttm=ttm1) \n",
    "        \n",
    "    #     delta_static = generator.get_delta(spot, 100, ttm1) - 1 # get_delta gives call delta, we're selling a put\n",
    "    #     delta2.append(delta_static)\n",
    "        \n",
    "    #     vals.append(val)\n",
    "    #     vals2.append(val2)\n",
    "    #     deltas.append(delta_barr)\n",
    "\n",
    "    # plt.plot(spots, deltas, label = \"DIP\")\n",
    "    # plt.plot(spots, delta2, label = \"Vanilla put\")\n",
    "    # plt.legend()\n",
    "    # plt.title(\"Delta comparison\")\n",
    "    # #plt.savefig('deltas_comparison')\n",
    "    # plt.show()\n",
    "\n",
    "    # plt.plot(spots, vals, label = \"DIP\")\n",
    "    # plt.plot(spots, vals2, label = \"Vanilla put\")\n",
    "    # plt.legend()\n",
    "    # plt.title(\"Value comparison\")\n",
    "    # #plt.savefig('vals_comparison')\n",
    "    # plt.show()\n",
    "\n",
    "    # diffs = np.array(deltas) - np.array(delta2)\n",
    "    # plt.plot(spots, diffs, label = \"DIP - Vanilla put\")\n",
    "    # plt.legend()\n",
    "    # plt.title(\"Difference in deltas\")\n",
    "    # #plt.savefig('delta_diff')\n",
    "    # plt.show()\n",
    "\n",
    "    # vals3 = []\n",
    "    # unds = []\n",
    "    # generator = GBM_Generator(100, r, sigma, freq)\n",
    "    # for i in range(100):\n",
    "    #     unds.append(generator.get_next())\n",
    "    #     vals3.append(generator.get_option_value(100,100-i,False))\n",
    "\n",
    "    # plt.figure(1)\n",
    "    # plt.subplot(121)\n",
    "    # plt.plot(vals3)\n",
    "    # plt.subplot(122)\n",
    "    # plt.plot(unds)\n",
    "    # plt.show()\n",
    "\n",
    "    model = PPO(policy=\"MlpPolicy\", \n",
    "                policy_kwargs=policy_kwargs,\n",
    "                env=env,\n",
    "                learning_rate=lr, \n",
    "                n_steps = epoch,\n",
    "                batch_size=batch_size,\n",
    "                n_epochs=n_epochs,\n",
    "                gamma = discount,\n",
    "                gae_lambda=gae_lambda,\n",
    "                clip_range=surrogate_loss_clip,\n",
    "                normalize_advantage=True,\n",
    "                ent_coef=entropy_weight,\n",
    "                vf_coef=value_weight,\n",
    "                max_grad_norm=gradient_max,\n",
    "                tensorboard_log='./runs/',\n",
    "                verbose=1)\n",
    "\n",
    "    generator = GBM_Generator(S0, r, sigma, freq, seed=123, barrier=barrier)\n",
    "    test_env_args = {\n",
    "        \"generator\" : generator,\n",
    "        \"ttm\" : ttm,\n",
    "        \"kappa\" : kappa,\n",
    "        \"cost_multiplier\" : cost_multiplier,\n",
    "        \"reward_type\" : \"static\",\n",
    "        \"testing\" : True,\n",
    "        \"n_puts_sold\" : n_puts_sold,\n",
    "        \"min_action\" : min_action,\n",
    "        \"max_action\" : max_action\n",
    "    }\n",
    "\n",
    "    test_env = BarrierEnv(**test_env_args)\n",
    "\n",
    "    model.learn(total_timesteps=max_episodes, callback=FigureRecorderCallback(test_env))\n",
    "    model.save('./weights_PPO/')\n",
    "\n",
    "    #####################################\n",
    "    ####### TESTING PHASE ###############\n",
    "    #####################################\n",
    "    \n",
    "    obs = test_env.reset()\n",
    "    df = simulate(test_env, obs)\n",
    "    # delta hedge benchmark\n",
    "    delta_agent = DeltaHedge(generator.initial, call = False, n_puts_sold=n_puts_sold, min_action=min_action)\n",
    "    obs = test_env.reset()\n",
    "    delta = delta_agent.test(test_env, obs)\n",
    "\n",
    "    Utils.plot_decisions(delta, df)\n",
    "    Utils.plot_pnl(delta, df)\n",
    "\n",
    "    pnl_paths_dict, pnl_dict, tcosts_dict, ntrades_dict = Utils.simulate_pnl(delta_agent, n_sim, test_env, simulate)\n",
    "    Utils.plot_pnl_hist(pnl_paths_dict, pnl_dict, tcosts_dict, ntrades_dict)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "7a5ba252f3d1a0a54b5a059d902dc08a13a5109b3692b2d6a8c956d84de3f1c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
